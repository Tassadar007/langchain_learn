{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SERPAPI_API_KEY']=\"\"\n",
    "os.environ['OPENAI_API_KEY']=\"\"\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"LangGraph\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SerpAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting google-search-results\n",
      "  Using cached google_search_results-2.4.2.tar.gz (18 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from google-search-results) (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from requests->google-search-results) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from requests->google-search-results) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from requests->google-search-results) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from requests->google-search-results) (2024.7.4)\n",
      "Building wheels for collected packages: google-search-results\n",
      "  Building wheel for google-search-results (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32009 sha256=b39c1d81d3995d2ff914bf3a28f31b56abdff26a07cf4432dd99dcaaa051e2b7\n",
      "  Stored in directory: /Users/yanglinshuo/Library/Caches/pip/wheels/0c/47/f5/89b7e770ab2996baf8c910e7353d6391e373075a0ac213519e\n",
      "Successfully built google-search-results\n",
      "Installing collected packages: google-search-results\n",
      "Successfully installed google-search-results-2.4.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install google-search-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Barack Hussein Obama II'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search=SerpAPIWrapper()\n",
    "search.run(\"Obama's first name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langgraph\n",
      "  Using cached langgraph-0.2.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.27 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langgraph) (0.2.30)\n",
      "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph)\n",
      "  Using cached langgraph_checkpoint-1.0.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (0.1.99)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langchain-core<0.3,>=0.2.27->langgraph) (4.12.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.27->langgraph) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.2.27->langgraph) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.3,>=0.2.27->langgraph) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.27->langgraph) (2024.7.4)\n",
      "Using cached langgraph-0.2.4-py3-none-any.whl (81 kB)\n",
      "Using cached langgraph_checkpoint-1.0.3-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: langgraph-checkpoint, langgraph\n",
      "Successfully installed langgraph-0.2.4 langgraph-checkpoint-1.0.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools, operator, requests, json\n",
    "from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from typing import Annotated, Any, Dict, Optional, Sequence, TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import (AIMessage, BaseMessage, ChatMessage,FunctionMessage, HumanMessage, SystemMessage)\n",
    "\n",
    "@tool(\"web_search\")\n",
    "def web_search(query: str) -> str:\n",
    "    \"\"\"Search with Google SERP API by a query\"\"\"\n",
    "    search = SerpAPIWrapper()\n",
    "    return search.run(query)\n",
    "\n",
    "@tool(\"twitter_writer\")\n",
    "def write_tweet(content: str) -> str:\n",
    "    \"\"\"Based a piece of content, write a tweet.\"\"\"\n",
    "    chat = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "    messages = [\n",
    "        SystemMessage(\n",
    "            content=\"You are a Twitter account operator. You a responsible for writting a tweet only based on the content given. You should follow the Twitter policy and make sure each tweet has no more than 140 characters.\"\n",
    "        ),\n",
    "        HumanMessage(\n",
    "            content=content\n",
    "        ),\n",
    "\n",
    "    ]\n",
    "    response = chat(messages)\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    # The annotation tells the graph that new messages will always\n",
    "    # be added to the current states\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    # The 'next' field indicates where to route to next\n",
    "    next: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(llm: ChatOpenAI, tools: list, system_prompt: str):\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", system_prompt),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "        ]\n",
    "    )\n",
    "    agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "    excutor = AgentExecutor(agent=agent, tools=tools)\n",
    "    return excutor\n",
    "\n",
    "def agent_node(state, agent, name):\n",
    "    result = agent.invoke(state)\n",
    "    return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "members = [\"Search_Engine\", \"Twitter_Writer\"]\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the following workers: {members}.\"\n",
    "    \" Given the following user requests, respond with the worker to act next. Each worker will perform a task and respond with their results and status.\"\n",
    "    \" Whtn finished, respond with FINISH.\"\n",
    ")\n",
    "\n",
    "options = [\"FINISH\"] + members\n",
    "# Using openai function calling can make output parsing easier for us\n",
    "function_def = {\n",
    "    \"name\": \"route\",\n",
    "    \"description\": \"Select the next role.\",\n",
    "    \"parameters\":{\n",
    "        \"title\": \"routeSchema\",\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"next\":{\n",
    "                \"title\": \"Next\",\n",
    "                \"anyOf\": [\n",
    "                    {\"enum\": options},\n",
    "                ],\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"next\"],\n",
    "    },\n",
    "}\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"system_prompt\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        (\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\",),\n",
    "    ]\n",
    ").partial(options=str(options), members=\", \".join(members))\n",
    "\n",
    "supervisor_chain = (\n",
    "    prompt\n",
    "    | llm.bind_functions(functions=[function_def], function_call=\"route\")\n",
    "    | JsonOutputFunctionsParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine_agent = create_agent(llm, [web_search], \"You are a web search engine.\")\n",
    "search_engine_node = functools.partial(agent_node, agent=search_engine_agent, name=\"Search_Engine\")\n",
    "\n",
    "twitter_operator_agent = create_agent(llm, [write_tweet], \"You are responsible for writting a tweet based on the content given.\")\n",
    "twitter_operator_node = functools. partial(agent_node, agent=twitter_operator_agent, name=\"Twitter_Writer\")\n",
    "\n",
    "workflow = StateGraph(AgentState)\n",
    "workflow.add_node(\"Search_Engine\", search_engine_node)\n",
    "workflow.add_node(\"Twitter_Writer\", twitter_operator_node)\n",
    "workflow.add_node(\"supervisor\", supervisor_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in members:\n",
    "    workflow.add_edge(member, \"supervisor\")\n",
    "\n",
    "conditional_map = {k: k for k in members}\n",
    "conditional_map[\"FINISH\"] = END\n",
    "workflow.add_conditional_edges(\"supervisor\", lambda x: x[\"next\"],conditional_map)\n",
    "workflow.set_entry_point(\"supervisor\")\n",
    "graph = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'supervisor': {'next': 'Twitter_Writer'}}\n",
      "----\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yanglinshuo/anaconda3/envs/streamlit/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The method `BaseChatModel.__call__` was deprecated in langchain-core 0.1.7 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Twitter_Writer': {'messages': [HumanMessage(content='ðŸš€ Exciting news! LangChain just dropped a major update enhancing API integration & boosting performance. A must for developers! #LangChain #AI #DevNews', name='Twitter_Writer')]}}\n",
      "----\n",
      "{'supervisor': {'next': 'FINISH'}}\n",
      "----\n"
     ]
    }
   ],
   "source": [
    "for s in graph.stream(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            HumanMessage(content=\"Write a tweet about LangChain news.\")\n",
    "        ]\n",
    "    }\n",
    "):\n",
    "    if \"__end__\" not in s:\n",
    "        print(s)\n",
    "        print(\"----\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "streamlit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
